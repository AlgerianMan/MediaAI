{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial image synthesis using an MNIST classifier\n",
    "\n",
    "This notebook utilizes the MNIST classifier of the previous tutorial.\n",
    "\n",
    "**Learning goals:**\n",
    "* Building and training a convolutional neural network on a bit lower level, mixing both Tensorflow and Keras, which allows us to perform more interesting manipulations.\n",
    "* Cloning built models\n",
    "* Synthesizing media as adversarial inputs to a classifier, in this case adversarial images.\n",
    "\n",
    "**After you've read, run, and understood the code, try to modify it as follows to test your learning:**\n",
    "\n",
    "*Note: we don't expect you to complete these all, we just provide many examples to illustrate that you can do quite many interesting things with a simple image classification network.*\n",
    "\n",
    "* Easy: Instead of optimizing the classification loss, optimize an image that maximizes some individual neuron's output. Hint: you can access the neuron outputs as ```model2.layers[layer_index].output```\n",
    "* Easy: Experiment with different starting images, and different network variations, e.g., amounts of drop-off. Also experiment in having the optimized image in a different resolution (you'll need to scale it for the network, though). Can you make more meaningful adversarial images emerge?\n",
    "* Advanced: Track a user using Kinect, OpenPose or equivalent. Render the user's skeleton or silhouette as a Numpy tensor and make a game or interactive installation where the user attempts to pose such that he/she is recognized as a number by the MNIST classifier network.\n",
    "* Advanced: Optimize the pose of an animated character such that the rendered silhouette makes the network think it's seeing numbers. You'll need to figure out a pipeline from an animation model to the silhouette rendered as a tensor that can be fed to the network. You can do the adversarial optimization either using a differentiable renderer like SoftRas as part of the compute graph and using a Tensorflow optimizer like Adam, or optimize the pose directly using CMA-ES or (LM-)MA-ES. We will talk about the latter two later on the course.\n",
    "\n",
    "**Note that you can also try all of the above with audio**. You just need some audio dataset for training and Conv1D instead of Conv2D layers, as audio data is typically handled as 3D tensors of shape [nBatch,nAudioSamples,nChannels]\n",
    "\n",
    "For more about mixing Keras and Tensorflow, see [https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html](https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and visualizing the data\n",
    "\n",
    "First, let's load the dataset using keras helpers and visualize some images using pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#The pylab inline below is something you may need to make images and plots visible in Jupyter, depending on your Anaconda setup\n",
    "%pylab inline  \n",
    "#This line of \"magic\" tells Google Colab which Tensorflow version to use. \n",
    "#The low-level tensorflow code in this tutorial does not work with Tensorflow 2.\n",
    "#If running this notebook outside Colab, comment the line out.\n",
    "%tensorflow_version 1.x\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pp\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" #disable Tensorflow GPU usage, a simple example like this runs faster on CPU\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "#from tensorflow import keras \n",
    "\n",
    "#load the MNIST dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#Scale the pixel intensity values to 0...1 from 0...255\n",
    "#Fortunately, we don't a StandardScaler here\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "#check the shape: you should see that x_train is a 3D tensor, \n",
    "#with 60000 instances of 2D tensors 28x28 pixels \n",
    "print(\"shape: \",x_train.shape)\n",
    "\n",
    "#because the keras layers we will use need explicitly defined pixel channel count as the fourth dimension,\n",
    "#we reshape:\n",
    "x_train=np.reshape(x_train,[x_train.shape[0],x_train.shape[1],x_train.shape[2],1])\n",
    "print(\"new shape: \",x_train.shape)\n",
    "\n",
    "#do the same for test data\n",
    "x_test=np.reshape(x_test,[x_test.shape[0],x_test.shape[1],x_test.shape[2],1])\n",
    "\n",
    "\n",
    "#visualize some of the images\n",
    "pp.figure(1)\n",
    "for i in range(8):\n",
    "    pp.subplot(1,8,1+i)\n",
    "    #imshow expects a 2d tensor, thus we pick the i:th image, full width and height, and the first and only color channel\n",
    "    pp.imshow(x_train[i,:,:,0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going more low-level with Keras and Tensorflow \n",
    "\n",
    "Keras models like the one used in the previous exercise are pretty much black boxes. If you want to hack together something more sophisticated, you'll often have to open the box a little. Below, we implement the following modifications:\n",
    "* We define the network's input explicitly as a placeholder tensor. This allows us to replace it with a variable that can be optimized for adversarial image generation.\n",
    "* We define the layers as above, but explicitly add an input layer\n",
    "* Instead of using model.compile() and model.fit(), we explicitly define the loss function and use a Tensorflow optimizer. This is now required as we have the explicit input layer. \n",
    "* We use another optimizer for adversarial image generation.\n",
    "\n",
    "*Pay particular attention to how one uses sess.run() to interact with the compute graph.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#In addition to the layers used before, we will need InputLayer, \n",
    "#which allows us to explicitly define the tensors that the network receives as inputs\n",
    "from tensorflow.keras.layers import Dense   #fully connected layer\n",
    "from tensorflow.keras.layers import Conv2D  #convolutional layer with 2D filters (for audio you would use 1D)\n",
    "from tensorflow.keras.layers import Flatten #converts images to plain vectors of numbers\n",
    "from tensorflow.keras.layers import Dropout #this mitigates overfitting\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "\n",
    "#When coding with \"raw\" tensorflow, one always needs a session variable. \n",
    "#We also reset the default graph which prevents things from slowing down if you run this Jupyter cell multiple times.\n",
    "#Otherwise, you would end up creating many redundant copies of the network.\n",
    "tf.reset_default_graph()\n",
    "sess=tf.InteractiveSession()\n",
    "\n",
    "#declare input placeholders to which to upload data\n",
    "nClasses=10\n",
    "tfX=tf.placeholder(dtype=tf.float32,shape=[None,28,28,1]);\n",
    "tfY=tf.placeholder(dtype=tf.int32,shape=[None]);\n",
    "\n",
    "#Build model the model. The difference to the previous tutorial is that we add the InputLayer.\n",
    "#We also omit the dropouts, as that makes it easier to demonstrate the adversarial optimization\n",
    "model = keras.models.Sequential()\n",
    "model.add(InputLayer(input_tensor=tfX,input_shape=(28,28,1,)))\n",
    "model.add(Conv2D(16, kernel_size=(5, 5), strides=[2,2],activation='relu'))\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), activation='relu', strides=[2,2]))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', strides=[2,2]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "output=model.output \n",
    "\n",
    "#With the input tensor defined, we can't anymore use model.compile() and model.fit(), as we must explicitly handle\n",
    "#the minibatches that go into the network. Thus, let's define the training loss and optimizer\n",
    "loss=tf.losses.sparse_softmax_cross_entropy(tfY,output)\n",
    "optimizer=tf.train.AdamOptimizer()\n",
    "\n",
    "#optimizer.minimize() gives us a special tensor. Optimization iterations are triggered when we fetch this tensor using sess.run()\n",
    "optimize=optimizer.minimize(loss)\n",
    "\n",
    "#initialize variables (another thing one needs to do when coding low-level)\n",
    "tf.global_variables_initializer().run(session=sess)\n",
    "\n",
    "#Optimize\n",
    "nIter=5000\n",
    "for iter in range(nIter):\n",
    "    #Extract a random minibatch from the data\n",
    "    nMinibatch=32\n",
    "    batchIndices=np.random.randint(0,x_train.shape[0],[nMinibatch])\n",
    "    batch_x,batch_y=x_train[batchIndices],y_train[batchIndices]\n",
    "    \n",
    "    #Use sess.run() to perform the optimization iterations.\n",
    "    #sess.run() is the main method for interacting with the compute graph: you fetch a number of tensors,\n",
    "    #and you pass in all inputs that the fetches require. Before a sess.run() call, there's no computation\n",
    "    #happening, and the code above just constructs the graph. This is a big conceptual difference to simply\n",
    "    #programming with numpy, where function calls directly modify tensor contents. \n",
    "    \n",
    "    #Furthermore, the tensors that one fetches may trigger all kinds of computations, e.g., the optimizer.\n",
    "    \n",
    "    #Here, the optimization and the loss function computing needs data for the tfX and tfY placeholder tensors.\n",
    "    #To make the Keras Dropout layers work, we also must pass in the learning_phase boolean\n",
    "    [temp,currLoss]=sess.run(fetches=[optimize,loss],feed_dict={\n",
    "        tfX:x_train[batchIndices],\n",
    "        tfY:y_train[batchIndices],\n",
    "        tf.keras.backend.learning_phase():True})\n",
    "    \n",
    "    #print progress every 100 iterations\n",
    "    if iter%100==0:\n",
    "        print(\"Iteration {}/{}, Loss {}\".format(iter,nIter,currLoss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as before, let's test the classifier with an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#this is the test image\n",
    "testIdx=0\n",
    "#Show the image\n",
    "print(\"Testing with image:\")\n",
    "pp.imshow(x_test[testIdx,:,:,0])\n",
    "pp.show()\n",
    "#We index by testIdx:testIdx+1 to pass a batch of one image to the network instead of just one image\n",
    "classProbabilities=sess.run(output,{tfX:x_test[testIdx:testIdx+1]})\n",
    "print(\"Predicted class probabilities: \",classProbabilities)\n",
    "#np.argmax returns the index of the largest value in a Numpy tensor.\n",
    "#np.max returns the largest value\n",
    "print(\"The most probable class is {}, with probability {}\".format(np.argmax(classProbabilities),np.max(classProbabilities)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial image generation\n",
    "\n",
    "Finally, to be able to optimize the adversarial images, we make a new copy of the network, but such that this one receives a tf.Variable() as its inputs. We can then optimize the variable just like we earlier optimized the network parameters. \n",
    "\n",
    "This illustrates the power of Tensorflow and other modern compute graph platforms: Anything can be optimized with respect to anything else, as long as the compute graph contains only differentiable operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#We define a variable of shape [1,28,28,1], i.e., a batch of a single image\n",
    "#Variables are special tensors that contain optimized parameters or other data\n",
    "#that one wants to store persistently.\n",
    "image=tf.Variable(dtype=tf.float32,initial_value=np.random.uniform(0,1,[1,28,28,1]))\n",
    "\n",
    "#The optimization may modify the image pixels arbitrarily. \n",
    "#We want to keep the pixel values between 0 and 1, which we can ensure\n",
    "#by using tanh function. Tanh output ranges from -1 to 1, which is why\n",
    "#we need the extra scaling\n",
    "image_clamped=0.5+0.5*tf.tanh(image)\n",
    "\n",
    "#Make a copy of the trained network but with new inputs\n",
    "model2=tf.keras.models.clone_model(model,image_clamped)\n",
    "\n",
    "#Copy weights\n",
    "model2.set_weights(model.get_weights())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to make sure the copying was successful, test the cloned model with the an image.\n",
    "\n",
    "**NOTE:** as the network's input is the variable, we don't feed the image as a parameter to sess.run()\n",
    "Instead, we load the image to the variable before calling sess.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "testIdx=0\n",
    "print(\"Testing cloned model with image:\")\n",
    "pp.imshow(x_test[testIdx,:,:,0])\n",
    "pp.show()\n",
    "image.load(np.reshape(x_test[testIdx],[1,28,28,1]))\n",
    "classProbabilities=sess.run(model2.output)\n",
    "print(\"Predicted class probabilities: \",classProbabilities)\n",
    "print(\"The most probable class is {}, with probability {}\".format(np.argmax(classProbabilities),np.max(classProbabilities)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start optimize the image until it gives some other class output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#We want the image to represent this class.\n",
    "targetClass=0\n",
    "\n",
    "#Now, we again need the classification loss, i.e., categorical cross-entropy.\n",
    "#For the loss function, we need to wrap the targetClass variable inside a Tensorflow constant tensor\n",
    "loss=tf.losses.sparse_softmax_cross_entropy(tf.constant([[targetClass]],dtype=int32),model2.output)\n",
    "\n",
    "#For debug, extract the target class probability\n",
    "targetClassProbability=model2.output[0,targetClass]\n",
    "\n",
    "#Create the optimization operation. We explicitly define that we want to only optimize the image,\n",
    "#because otherwise the network's parameters would get changed too.\n",
    "optimizeAdversarial=tf.train.AdamOptimizer().minimize(loss,var_list=[image])\n",
    "\n",
    "#Now a bit of a kludge: because we created a new optimizer, we must run \n",
    "#the Tensorflow global variables initializer again, and this will re-randomize our model weights.\n",
    "#Thus, we first save the weights and then reload them after running the initializer\n",
    "weights=model2.get_weights()\n",
    "tf.global_variables_initializer().run(session=sess)\n",
    "model2.set_weights(weights)\n",
    "\n",
    "#This is our initial image\n",
    "image.load(np.random.uniform(0,1,[1,28,28,1]),sess) \n",
    "\n",
    "#Optimize\n",
    "nIter=10000\n",
    "images=[]  #we will store intermediate results here\n",
    "for iter in range(nIter+1):\n",
    "    #here, sess.run() is simple, as we don't have to feed any placeholders\n",
    "    [temp,currLoss,currProb]=sess.run(fetches=[optimizeAdversarial,loss,targetClassProbability])\n",
    "    #print and show progress\n",
    "    if iter%1000==0:\n",
    "        #print current target class probability\n",
    "        print(\"Iteration {}/{}, Loss {}, Target class probability {}\".format(iter,nIter,currLoss,currProb))\n",
    "        #fetch and store the current image\n",
    "        images.append(sess.run(image)[0,:,:,0])\n",
    "\n",
    "#Display the images        \n",
    "nImages=len(images)\n",
    "pp.figure(1,figsize(nImages*2,2))\n",
    "for i in range(nImages):\n",
    "    pp.subplot(1,nImages,1+i)\n",
    "    pp.imshow(images[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
