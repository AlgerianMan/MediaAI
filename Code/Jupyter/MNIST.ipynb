{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification with MNIST data, with visualization of the results\n",
    "\n",
    "This notebook shows how to train a convolutional image recognition network for recognizing hand-written digits from the MNIST dataset. This is the \"hello world\" example of deep learning, and later on we will also have some artistic use for it. \n",
    "\n",
    "**Learning goals:**\n",
    "* Building a simple convolutional neural network\n",
    "* Useful debugging skills: visualizing errors, visualizing neural network weights\n",
    "\n",
    "**After you've read, run, and understood the code, try to modify it as follows to test your learning:**\n",
    "\n",
    "* Easy: try adding 1 or more fully connected layers, e.g., with 64 neurons before the output layer of the fully connected network example. How do the first layer weights look like now?\n",
    "* Easy: Pass in an artificial image and check what class it is classified into. Hint: you can \"paint\" rectancles by first creating an empty single image batch as ```image=np.zeros([1,28,28,1])```, and then setting rectangular patches to 1 as ```image[0,y0:y1,x0:x1,0]=1```, where x0,x1,y0,y1 are the rectangle corners. Feel free to also explore more sophisticated drawing methods, e.g., from the skimage library. \n",
    "* A bit harder: Visualize the test image (or multiple images) that gives the lowest probability for the correct class. Hint: if you pass a batch of test images to model.predict(), you will get a batch of probabilities back, one vector of 10 probabilities for each image.\n",
    "* Harder: Visualize how well the network learns features that make the number classes separate. Use principal component analysis (PCA) of the flattened layer outputs, and make a 2D scatterplot of each input image's projection into the 2D subspace defined by the first two principal axes. Numpy provides easy helpers for PCA, just google it up. Do the same for different layer outputs; you should see that the classes overlap less and less as the images pass through the network and training progresses.\n",
    "* Advanced: Develop a game where the player has to draw images that score high classification probabilities with as few pixels as possible. For this, you should either load the network to Unity using Tensorflow Sharp, or experiment with Python's mouse input etc. Obviously, such interaction is not possible inside Jupyter, so you should develop using some other IDE such as Visual Studio, Pycharm, or Spyder (the latter is included in Anaconda)\n",
    "\n",
    "As usual, model solutions are provided for the easy exercises, but please try to think of this as a puzzle game where you first try to solve the puzzles yourself and only check out the walkthrough if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and visualizing the data\n",
    "\n",
    "First, let's load the dataset using keras helpers and visualize some images using pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#The pylab inline below is something you may need to make images and plots visible in Jupyter, depending on your Anaconda setup\n",
    "%pylab inline  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pp\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" #disable Tensorflow GPU usage, a simple example like this runs faster on CPU\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "\n",
    "#load the MNIST dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#Scale the pixel intensity values to 0...1 from 0...255\n",
    "#Fortunately, we don't need a StandardScaler here\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "#check the shape: you should see that x_train is a 3D tensor, \n",
    "#with 60000 instances of 2D tensors 28x28 pixels \n",
    "print(\"shape: \",x_train.shape)\n",
    "\n",
    "#because the keras layers we will use need explicitly defined pixel channel count as the fourth dimension,\n",
    "#we reshape:\n",
    "x_train=np.reshape(x_train,[x_train.shape[0],x_train.shape[1],x_train.shape[2],1])\n",
    "print(\"new shape: \",x_train.shape)\n",
    "\n",
    "#do the same for test data\n",
    "x_test=np.reshape(x_test,[x_test.shape[0],x_test.shape[1],x_test.shape[2],1])\n",
    "\n",
    "\n",
    "#visualize some of the images\n",
    "pp.figure(1)\n",
    "for i in range(8):\n",
    "    pp.subplot(1,8,1+i)\n",
    "    #imshow expects a 2d tensor, thus we pick the i:th image, full width and height, and the first and only color channel\n",
    "    pp.imshow(x_train[i,:,:,0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple fully connected network model\n",
    "Before training the convolutional neural network, let's first establish a baseline using a fully connected network similar to what we used in the previous example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Let's import the layer types we need\n",
    "from tensorflow.keras.layers import Dense   #fully connected layer\n",
    "from tensorflow.keras.layers import Flatten #converts images to vectors of numbers\n",
    "\n",
    "#As before, we use a simply sequential, i.e., multilayer architecture\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "#Flatten converts a batch of multidimensional data into a batch of 1D data. \n",
    "#This is what the fully connected layers expect.\n",
    "#For example, the rows of an image are simply stacked after each other.\n",
    "#If the data was not images, we would not need this.\n",
    "model.add(Flatten())\n",
    "\n",
    "#The output layer is fully connected, with 1 neuron for each 10 classes.\n",
    "#For classification, one should use the softmax activation.\n",
    "#This means that each output neuron can be thought as the probability of a class.\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#Compile the model. We use sparse_categorical_crossentropy loss instead of categorical_crossentropy,\n",
    "#because the label data contains indices instead of one-hot vectors\n",
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Train the network\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=5,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a fully connected network, the neuron weights are of the same shape as the input. Thus, we can visualize them as images. Below, you should see that a fully connected network does not learn to detect edges, corners etc but instead shapes that correlate with whole input images. This is not very efficient but might be of use in artistic image synthesis.\n",
    "\n",
    "Because we only have a single layer with a single neuron for each output class, the neuron weight images actually look like numbers. Bright pixels mean large weights, i.e., if the input image has pixels in those areas, the probability of the class corresponding to the neuron will be high. Conversely, dark pixels mean small or negative weighs, i.e., the probability decreases if the input has pixels in those areas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Visualize some of the first layer neuron weights\n",
    "#First, query the weights. We use index 1 because index 0 is the flatten layer\n",
    "weights=model.layers[1].get_weights()[0]\n",
    "#Create a figure with appropriate size\n",
    "nNeuronsToVisualize=10\n",
    "pp.figure(1,figsize=[nNeuronsToVisualize*2,2])\n",
    "#Loop over the neurons\n",
    "for i in range(nNeuronsToVisualize):\n",
    "    #Weights is a 2D tensor where the first dimension indexes over data variables, second over neurons\n",
    "    image=weights[:,i]\n",
    "    #We must reshape back to an image\n",
    "    image=np.reshape(image,[28,28])\n",
    "    #Now we can display\n",
    "    pp.subplot(1,nNeuronsToVisualize,1+i)\n",
    "    pp.title(\"Neuron {}\".format(i))\n",
    "    pp.imshow(image)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A convolutional neural network \n",
    "\n",
    "The accuracy of the network trained above is not great. State of the art gets to over 99\\% with MNIST data. Even a simple convolutional network will get us much closer to that. Note that this mainly differs from the previous network with respect to the first layers; a convolutional neural network typically ends with a fully connected network, starting with the flatten layer.\n",
    "\n",
    "Note that this simple Keras model doesn't provide us access to things we will need for many interesting modifications, and we'll later rebuild the same network a bit differently in the [adversarial image generation exercise](AdversarialMNIST.ipynb). However, the code below is a better pedagogical fit for this exercise, as this is the way you've used Keras in the previous examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Let's import the layer types we need\n",
    "from tensorflow.keras.layers import Dense   #fully connected layer\n",
    "from tensorflow.keras.layers import Conv2D  #convolutional layer with 2D filters (for audio you would use 1D)\n",
    "from tensorflow.keras.layers import Dropout #this mitigates overfitting\n",
    "\n",
    "#As before, we use a simply sequential, i.e., multilayer architecture\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "#Instead of using fully connected layers like before, we use convolutional ones.\n",
    "#We use 5x5 pixel features, and use strides of 2x2 to drop resolution by a factor of 2 after each layer\n",
    "model.add(Conv2D(16, kernel_size=(5, 5), strides=[2,2],\n",
    "                 activation='relu',\n",
    "                 input_shape=(28,28,1,)))\n",
    "model.add(Conv2D(32, (5, 5), activation='relu', strides=[2,2]))\n",
    "#After the previous two layers, we are at 7x7 pixel resolution instead of the original 28x28 pixels.\n",
    "#Thus, 5x5 filters would not be meaningful, as they would encompass almost the whole images\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', strides=[2,2]))\n",
    "\n",
    "#Now, we are at 3x3 pixel resolution and there's no point in doing convolutions anymore.\n",
    "#Instead, we'll just add a small fully connected layer just like above\n",
    "#Again, we first need to flatten from a batch of images to a batch of 1D tensors\n",
    "model.add(Flatten())\n",
    "#Some regularization\n",
    "model.add(Dropout(0.5))\n",
    "#One fully connected\n",
    "model.add(Dense(32, activation='relu'))\n",
    "#More regularization\n",
    "model.add(Dropout(0.5))\n",
    "#Last fully connected layer, with softmax activation, which is what one needs for classification.\n",
    "#Softmax means that each output neuron can be thought as the probability of a class.\n",
    "#We use 10 neurons because MNIST has 10 classes.\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#Compile the model. We use sparse_categorical_crossentropy loss instead of categorica_crossentropy,\n",
    "#because the label data contains indices instead of one-hot vectors\n",
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Train the network\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=5,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the classifier with an images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#this is the test image\n",
    "testIdx=0\n",
    "#Show the image\n",
    "print(\"Testing with image:\")\n",
    "pp.imshow(x_test[testIdx,:,:,0])\n",
    "pp.show()\n",
    "#We index by testIdx:testIdx+1 to pass a batch of one image to the network instead of just one image\n",
    "classProbabilities=model.predict(x_test[testIdx:testIdx+1])\n",
    "print(\"Predicted class probabilities: \",classProbabilities)\n",
    "#np.argmax returns the index of the largest value in a Numpy tensor.\n",
    "#np.max returns the largest value\n",
    "print(\"Most probable class is {}, with probability {}\".format(np.argmax(classProbabilities),np.max(classProbabilities)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try to see what the network has learned. Research shows that the first layer of a convolutional image classification network should learn something like detectors for oriented edges or similar simple features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Define a visualization helper\n",
    "\n",
    "def visualizeLayerWeights(model,layerIndex):\n",
    "    #Get the neuron weights, i.e., convolution kernels or filters\n",
    "    kernel=model.layers[layerIndex].get_weights()[0]\n",
    "    #Check the shape\n",
    "    print(\"Visualizing layer {} kernel, shape {}\".format(layerIndex,kernel.shape))\n",
    "    #Visualize 16 first filters\n",
    "    nFiltersToVisualize=16\n",
    "    pp.figure(1,figsize=[nFiltersToVisualize*2,2])  #specify figsize explicitly because otherwise the images will be too small\n",
    "    for i in range(nFiltersToVisualize):\n",
    "        pp.subplot(1,nFiltersToVisualize,1+i)\n",
    "        pp.imshow(kernel[:,:,0,i])\n",
    "    pp.show()\n",
    "    \n",
    "#visualize first layer\n",
    "visualizeLayerWeights(model,0)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
