{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract adversarial images synthesized using CMA-ES\n",
    "This notebook shows how to synthesize abstract \"paintings\" through optimization. We use CMA-ES to optimize the corner positions of a number of rectangles. The objective function is the loss function of an MNIST image classifier network. In effect, we will synthesize images using the MNIST classifier as an \"art critic\". This allows us to understand what features the network finds essential. Depending on the painting method and network, the results can also be aesthetically interesting.\n",
    "\n",
    "This is also called adversarial image synthesis, i.e., fooling a trained image classifier. In come cases, this can also be done using Tensorflow's optimizers like Adam, as shown in the  [AdversarialMNIST notebook](AdversarialMNIST.ipynb). However, CMA-ES provides more flexibility, as it does not require the drawing functions to be differentiable. Optimizing something else than raw pixels makes the adversarial images somewhat recognizable to human eye. \n",
    "\n",
    "NOTE: if your Anaconda environment does not have CMA-ES installed, use ```pip install cma``` from the terminal. You may also need ```pip install scikit-image``` for the drawing methods.\n",
    "\n",
    "**Learning goals:**\n",
    "* Using a convolutional neural network image classifier for image synthesis.  \n",
    "* Using CMA-ES with the ```cma``` python package. \n",
    "\n",
    "**After you've read, run, and understood the code, try to modify it as follows to test your learning:**\n",
    "\n",
    "* Easy: try modifying the network architecture. How does, e.g., omitting the dropout layers or adding or removing neurons affect the results?\n",
    "* Easy: try changing the drawing style, e.g., use lines instead of rectangles.\n",
    "* Slightly harder: try using some other image classifier network. For example, [this repository](https://github.com/geifmany/cifar-vgg) provides pre-trained networks for the CIFAR-10 and CIFAR-100 datasets, i.e., 32x32 pixel images of buildings, birds, boats etc. You should be able to load the pretrained .md5 models using the ```keras.models.load_model()``` method.\n",
    "* Harder: train multiple networks and use their average output probabilities as the objective. How does this affect the results? Papers like [this one](https://arxiv.org/abs/1802.08195) suggest that using an ensemble of multiple networks is harder to fool by adversarial images. adding 1 or more fully connected layers, e.g., with 64 neurons before the output layer of the fully connected network example. How do the first layer weights look like now?\n",
    "* Harder: Make the code run faster by querying the loss function values for a batch of images. This allows Tensorflow to more efficiently parallelize the computation. For this, you probably need to implement the network on a slightly lower level so that you can use sess.run(). See the [AdversarialMNIST notebook](AdversarialMNIST.ipynb) for an example.\n",
    "* Hard: Implement the same in Unity. For example, if you optimize the pose of an animated character, can you make it's shadow appear as numbers, animals, etc.? For this, you need to use Tensorflow Sharp to load a pretrained classifier network and then feed a camera textures to the classifier. You can use the (LM-)MA-ES implementation provided in the course repository for the optimization.\n",
    "\n",
    "As usual, model solutions are provided for the easy exercises, but please try to think of this as a puzzle game where you first try to solve the puzzles yourself and only check out the walkthrough if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the MNIST classifier\n",
    "\n",
    "First, let's load the MNIST dataset and train the classifier. See the [MNIST tutorial](MNIST.ipynb) for a more thoroughly commented version of the same code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#The pylab inline below is something you may need to make images and plots visible in Jupyter, depending on your Anaconda setup\n",
    "%pylab inline  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pp\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" #disable Tensorflow GPU usage, a simple example like this runs faster on CPU\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.layers import Dense   \n",
    "from tensorflow.keras.layers import Conv2D  \n",
    "from tensorflow.keras.layers import Dropout \n",
    "from tensorflow.keras.layers import Flatten \n",
    "import cma  #this is the CMA-ES library\n",
    "\n",
    "#Load the MNIST dataset, scale pixel values to 0...1, reshape\n",
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train=np.reshape(x_train,[x_train.shape[0],x_train.shape[1],x_train.shape[2],1])\n",
    "x_test=np.reshape(x_test,[x_test.shape[0],x_test.shape[1],x_test.shape[2],1])\n",
    "\n",
    "#Build the network\n",
    "model = keras.models.Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(5, 5), strides=[2,2],activation='relu',input_shape=(28,28,1,)))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu', strides=[2,2]))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', strides=[2,2]))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Train the network\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=12,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the network is trained, we can proceed to the actual image synthesis. We first define some helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import skimage.draw as draw\n",
    "\n",
    "#Line drawing helper\n",
    "def drawLine(image:np.array,r0:int,c0:int,r1:int,c1:int,color:float=1.0):\n",
    "    rr, cc = draw.line(r0,c0,r1,c1)\n",
    "    image[rr, cc] = color\n",
    "\n",
    "#Rectangle drawing helper\n",
    "def drawRectangle(image:np.array,x0,y0,x1,y1,color:float=1.0):\n",
    "    #rectangle(start, extent=extent, shape=img.shape)\n",
    "    xmin=min([x0,x1])\n",
    "    ymin=min([y0,y1])\n",
    "    xmax=max([x0,x1])\n",
    "    ymax=max([y0,y1])\n",
    "    image[ymin:ymax+1,xmin:xmax+1]=color\n",
    "    #rr,cc=draw.rectangle(start=(xmin,ymin),extent=(xmax-xmin,ymax-ymin),shape=image.shape)\n",
    "    #image[rr, cc] = color\n",
    "    \n",
    "#Convert a single image to tensorflow image batch\n",
    "def im2batch(image:np.array):\n",
    "    return np.reshape(image,[1,image.shape[0],image.shape[1],1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the optimization is easy as: \n",
    "\n",
    "1) We query for new **x** to evaluate using cmaes.ask()\n",
    "\n",
    "2) Evaluate f(**x**) for each **x**\n",
    "\n",
    "3) Feed the f(**x**) values back to the optimizer using cmaes.tell()\n",
    "\n",
    "4) Repeat until maximum iteration count exceeded\n",
    "\n",
    "However, we must first define some parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#This is how many primitives (in this case: rectangles) we will use\n",
    "nPrimitives=3\n",
    "\n",
    "#How many optimized variables per primitive. \n",
    "#In total, defining the corners of each rectangle requires 4 variables\n",
    "nVarsPerPrimitive=4\n",
    "\n",
    "#How many total optimized variables\n",
    "nVars=nPrimitives*nVarsPerPrimitive\n",
    "print(\"Total number of optimized variables\",nVars)\n",
    "\n",
    "#Width and height of optimized image, 28 for MNIST\n",
    "imageReso=28\n",
    "\n",
    "#Which image class we want to synthesize\n",
    "targetClass=4\n",
    "\n",
    "#Define CMA-ES population size\n",
    "pop_size = 4 + int(3.0*math.log(nVars)) #recommended default for CMA-ES in Hansen's tutorial\n",
    "pop_size*=20  #increase population size because this is a hard problem\n",
    "cmaes_options = {'popsize': pop_size}  #the constructor below needs this\n",
    "\n",
    "#Define initial mean and standard deviation for the variables.\n",
    "#These should be set such that the initial Gaussian distribution of CMA-ES covers the whole range\n",
    "#We use 0 and 1, as we will later use np.sin() or np.tanh() to clamp the values to valid range\n",
    "startingMean=0\n",
    "startingSigma=1\n",
    "\n",
    "#Create the CMA-ES optimizer\n",
    "cmaes=cma.CMAEvolutionStrategy(np.ones(nVars)*startingMean, startingSigma, inopts=cmaes_options)\n",
    "\n",
    "#Variables for remembering the best painting and f(x) value found so far\n",
    "bestArt=None\n",
    "bestFx=np.inf\n",
    "\n",
    "#The main optimization loop\n",
    "nIter=10\n",
    "pp.figure(1,figsize=[nIter*3,3])\n",
    "for iter in range(nIter):\n",
    "    #Ask for a batch of x\n",
    "    xBatch=cmaes.ask()\n",
    "    \n",
    "    #Array to hold the f(x) values\n",
    "    fxBatch=[]\n",
    "    \n",
    "    #Loop over the batch\n",
    "    for x in xBatch:\n",
    "        #Create the drawing:\n",
    "        #First initialize the image to constant color\n",
    "        art=np.ones(shape=[imageReso,imageReso])\n",
    "        \n",
    "        #Make sure that the x given by CMA-ES stays within limits\n",
    "        #You can also try the other two options for slightly different results\n",
    "        x=0.5+0.5*np.sin(x)    #clip without saturating\n",
    "        #x=0.5+0.5*np.tanh(x)  #clip with soft saturation\n",
    "        #x=0.5+0.5*np.clip(x,-1,1) #hard clip\n",
    "        \n",
    "        #Now, we scale to image coordinates. We multiply x with slightly less than 1 to ensure that\n",
    "        #we stay in the range 0...imageReso-1 after converting to integers\n",
    "        x=0.999*imageReso*x\n",
    "        \n",
    "        #Draw all the rectangles by increasing the brightness of pixel values\n",
    "        for i in np.arange(0,nVarsPerPrimitive*nPrimitives,nVarsPerPrimitive):\n",
    "            #Draw\n",
    "            drawRectangle(art,int(x[i]),int(x[i+1]),int(x[i+2]),int(x[i+3]),color=0)\n",
    "            #Ensure that brightness stays within bounds\n",
    "            #art=np.clip(art,0,1)\n",
    "\n",
    "        #Evaluate the fitness function value. \n",
    "        #model.evaluate() gives us the loss function value and classification accuracy,\n",
    "        #thus model.evaluate()[0] is the loss function value, which we use as the f(x) minimized by CMA-ES \n",
    "        labelBatch=np.zeros(shape=[1,1])\n",
    "        labelBatch[0,0]=targetClass\n",
    "        fx=model.evaluate(im2batch(art), labelBatch, verbose=0)[0]\n",
    "        fxBatch.append(fx)\n",
    "\n",
    "        #If we found anew best value, remember the painting for visualization\n",
    "        if fx<bestFx:\n",
    "            bestFx=fx\n",
    "            bestArt=art.copy()\n",
    "    \n",
    "    #Feed the objective function values back to CMA-ES\n",
    "    cmaes.tell(solutions=xBatch,function_values=fxBatch)\n",
    "    \n",
    "    #Print progress\n",
    "    print(\"iter \",iter,\" best f(x) \",bestFx,end='\\r')\n",
    "\n",
    "    #Visualize\n",
    "    pp.subplot(1,nIter,1+iter)\n",
    "    pp.imshow(bestArt)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a version that optimizes a whole MNIST \"font\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#This is how many primitives (in this case: rectangles) we will use\n",
    "nPrimitives=3\n",
    "\n",
    "#How many optimized variables per primitive. \n",
    "#In total, defining the corners of each rectangle requires 4 variables\n",
    "nVarsPerPrimitive=4\n",
    "\n",
    "#How many total optimized variables\n",
    "nVars=nPrimitives*nVarsPerPrimitive\n",
    "print(\"Total number of optimized variables\",nVars)\n",
    "\n",
    "#Width and height of optimized image, 28 for MNIST\n",
    "imageReso=28\n",
    "\n",
    "#Define CMA-ES population size\n",
    "pop_size = 4 + int(3.0*math.log(nVars)) #recommended default for CMA-ES in Hansen's tutorial\n",
    "pop_size*=20  #increase population size because this is a hard problem\n",
    "cmaes_options = {'popsize': pop_size}  #the constructor below needs this\n",
    "\n",
    "#Define initial mean and standard deviation for the variables.\n",
    "#These should be set such that the initial Gaussian distribution of CMA-ES covers the whole range\n",
    "#We use 0 and 1, as we will later use np.sin() or np.tanh() to clamp the values to valid range\n",
    "startingMean=0\n",
    "startingSigma=1\n",
    "\n",
    "#We will produce a 5-by-2 grid figure\n",
    "pp.figure(1,figsize=[5*3,2*3])\n",
    "\n",
    "#Loop over all 10 MNIST classes\n",
    "for targetClass in range(10):\n",
    "    #Create the CMA-ES optimizer\n",
    "    cmaes=cma.CMAEvolutionStrategy(np.ones(nVars)*startingMean, startingSigma, inopts=cmaes_options)\n",
    "\n",
    "    #Variables for remembering the best painting and f(x) value found so far\n",
    "    bestArt=None\n",
    "    bestFx=np.inf\n",
    "\n",
    "    #The main optimization loop\n",
    "    for iter in range(10):\n",
    "        #Ask for a batch of x\n",
    "        xBatch=cmaes.ask()\n",
    "\n",
    "        #Array to hold the f(x) values\n",
    "        fxBatch=[]\n",
    "\n",
    "        #Loop over the batch\n",
    "        for x in xBatch:\n",
    "            #Create the drawing:\n",
    "            #First initialize the image to constant color\n",
    "            art=np.ones(shape=[imageReso,imageReso])\n",
    "\n",
    "            #Make sure that the x given by CMA-ES stays within limits\n",
    "            #You can also try the other two options for slightly different results\n",
    "            x=0.5+0.5*np.sin(x)    #clip without saturating\n",
    "            #x=0.5+0.5*np.tanh(x)  #clip with soft saturation\n",
    "            #x=0.5+0.5*np.clip(x,-1,1) #hard clip\n",
    "\n",
    "            #Now, we scale to image coordinates. We multiply x with slightly less than 1 to ensure that\n",
    "            #we stay in the range 0...imageReso-1 after converting to integers\n",
    "            x=0.999*imageReso*x\n",
    "\n",
    "            #Draw all the rectangles by increasing the brightness of pixel values\n",
    "            for i in np.arange(0,nVarsPerPrimitive*nPrimitives,nVarsPerPrimitive):\n",
    "                #Draw\n",
    "                drawRectangle(art,int(x[i]),int(x[i+1]),int(x[i+2]),int(x[i+3]),color=0)\n",
    "                #Ensure that brightness stays within bounds\n",
    "                #art=np.clip(art,0,1)\n",
    "\n",
    "            #Evaluate the fitness function value. \n",
    "            #model.evaluate() gives us the loss function value and classification accuracy,\n",
    "            #thus model.evaluate()[0] is the loss function value, which we use as the f(x) minimized by CMA-ES \n",
    "            labelBatch=np.zeros(shape=[1,1])\n",
    "            labelBatch[0,0]=targetClass\n",
    "            fx=model.evaluate(im2batch(art), labelBatch, verbose=0)[0]\n",
    "            fxBatch.append(fx)\n",
    "\n",
    "            #If we found anew best value, remember the painting for visualization\n",
    "            if fx<bestFx:\n",
    "                bestFx=fx\n",
    "                bestArt=art.copy()\n",
    "\n",
    "        #Feed the objective function values back to CMA-ES\n",
    "        cmaes.tell(solutions=xBatch,function_values=fxBatch)\n",
    "\n",
    "        #Print progress\n",
    "        print(\"optimizing number \",targetClass,\", iteration \",iter,\" best f(x) \",bestFx,end='\\r')\n",
    "\n",
    "    #Visualize\n",
    "    pp.subplot(2,5,1+targetClass)\n",
    "    pp.imshow(bestArt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
