{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification with MNIST data, solutions to exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and visualizing the data\n",
    "\n",
    "First, let's load the dataset using keras helpers and visualize some images using pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#The pylab inline below is something you may need to make images and plots visible in Jupyter, depending on your Anaconda setup\n",
    "%pylab inline  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pp\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" #disable Tensorflow GPU usage, a simple example like this runs faster on CPU\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "\n",
    "#load the MNIST dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#Scale the pixel intensity values to 0...1 from 0...255\n",
    "#Fortunately, we don't a StandardScaler here\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "#check the shape: you should see that x_train is a 3D tensor, \n",
    "#with 60000 instances of 2D tensors 28x28 pixels \n",
    "print(\"shape: \",x_train.shape)\n",
    "\n",
    "#because the keras layers we will use need explicitly defined pixel channel count as the fourth dimension,\n",
    "#we reshape:\n",
    "x_train=np.reshape(x_train,[x_train.shape[0],x_train.shape[1],x_train.shape[2],1])\n",
    "print(\"new shape: \",x_train.shape)\n",
    "\n",
    "#do the same for test data\n",
    "x_test=np.reshape(x_test,[x_test.shape[0],x_test.shape[1],x_test.shape[2],1])\n",
    "\n",
    "\n",
    "#visualize some of the images\n",
    "pp.figure(1)\n",
    "for i in range(8):\n",
    "    pp.subplot(1,8,1+i)\n",
    "    #imshow expects a 2d tensor, thus we pick the i:th image, full width and height, and the first and only color channel\n",
    "    pp.imshow(x_train[i,:,:,0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Adding more layers to the fully connected network\n",
    "The first exercise was to simply add more layers. We only need one line of code per layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Let's import the layer types we need\n",
    "from tensorflow.keras.layers import Dense   #fully connected layer\n",
    "from tensorflow.keras.layers import Flatten #converts images to vectors of numbers\n",
    "\n",
    "#As before, we use a simply sequential, i.e., multilayer architecture\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "#Flatten converts a batch of multidimensional data into a batch of 1D data. \n",
    "#This is what the fully connected layers expect.\n",
    "#For example, the rows of an image are simply stacked after each other.\n",
    "#If the data was not images, we would not need this.\n",
    "model.add(Flatten())\n",
    "\n",
    "#This is the extra layer. You can try modifying the neuron and layer counts and see how the neuron weights and classification accuracy change\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "#The output layer is fully connected, with 1 neuron for each 10 classes.\n",
    "#For classification, one should use the softmax activation.\n",
    "#This means that each output neuron can be thought as the probability of a class.\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#Compile the model. We use sparse_categorical_crossentropy loss instead of categorical_crossentropy,\n",
    "#because the label data contains indices instead of one-hot vectors\n",
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Train the network\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=5,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the first layer weights similar to before. Note that for the second layer, we will have as many inputs as the previous layer has neurons, and the input tensors can no longer be interpreted as images. You could, however, try investigating those weights by synthesizing (optimizing) an input image that maximally excites a neuron. This is one of the exercises in the [Adversarial MNIST](AdversarialMNIST.ipynb) tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Visualize some of the first layer neuron weights\n",
    "#First, query the weights. We use index 1 because index 0 is the flatten layer\n",
    "weights=model.layers[1].get_weights()[0]\n",
    "#Create a figure with appropriate size\n",
    "nNeuronsToVisualize=10\n",
    "pp.figure(1,figsize=[nNeuronsToVisualize*2,2])\n",
    "#Loop over the neurons\n",
    "for i in range(nNeuronsToVisualize):\n",
    "    #Weights is a 2D tensor where the first dimension indexes over data variables, second over neurons\n",
    "    image=weights[:,i]\n",
    "    #We must reshape back to an image\n",
    "    image=np.reshape(image,[28,28])\n",
    "    #Now we can display\n",
    "    pp.subplot(1,nNeuronsToVisualize,1+i)\n",
    "    pp.title(\"Neuron {}\".format(i))\n",
    "    pp.imshow(image)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A convolutional neural network \n",
    "\n",
    "For the rest of the exercises, we again train a convolutional neural network, which gives better classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Let's import the layer types we need\n",
    "from tensorflow.keras.layers import Dense   #fully connected layer\n",
    "from tensorflow.keras.layers import Conv2D  #convolutional layer with 2D filters (for audio you would use 1D)\n",
    "from tensorflow.keras.layers import Dropout #this mitigates overfitting\n",
    "\n",
    "#As before, we use a simply sequential, i.e., multilayer architecture\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "#Instead of using fully connected layers like before, we use convolutional ones.\n",
    "#We use 5x5 pixel features, and use strides of 2x2 to drop resolution by a factor of 2 after each layer\n",
    "model.add(Conv2D(16, kernel_size=(5, 5), strides=[2,2],\n",
    "                 activation='relu',\n",
    "                 input_shape=(28,28,1,)))\n",
    "model.add(Conv2D(32, (5, 5), activation='relu', strides=[2,2]))\n",
    "#After the previous two layers, we are at 7x7 pixel resolution instead of the original 28x28 pixels.\n",
    "#Thus, 5x5 filters would not be meaningful, as they would encompass almost the whole images\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', strides=[2,2]))\n",
    "\n",
    "#Now, we are at 3x3 pixel resolution and there's no point in doing convolutions anymore.\n",
    "#Instead, we'll just add a small fully connected layer just like above\n",
    "#Again, we first need to flatten from a batch of images to a batch of 1D tensors\n",
    "model.add(Flatten())\n",
    "#Some regularization\n",
    "model.add(Dropout(0.5))\n",
    "#One fully connected\n",
    "model.add(Dense(32, activation='relu'))\n",
    "#More regularization\n",
    "model.add(Dropout(0.5))\n",
    "#Last fully connected layer, with softmax activation, which is what one needs for classification.\n",
    "#Softmax means that each output neuron can be thought as the probability of a class.\n",
    "#We use 10 neurons because MNIST has 10 classes.\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#Compile the model. We use sparse_categorical_crossentropy loss instead of categorica_crossentropy,\n",
    "#because the label data contains indices instead of one-hot vectors\n",
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Train the network\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=5,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the classifier with an images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#this is the test image\n",
    "testIdx=0\n",
    "#Show the image\n",
    "print(\"Testing with image:\")\n",
    "pp.imshow(x_test[testIdx,:,:,0])\n",
    "pp.show()\n",
    "#We index by testIdx:testIdx+1 to pass a batch of one image to the network instead of just one image\n",
    "classProbabilities=model.predict(x_test[testIdx:testIdx+1])\n",
    "print(\"Predicted class probabilities: \",classProbabilities)\n",
    "#np.argmax returns the index of the largest value in a Numpy tensor.\n",
    "#np.max returns the largest value\n",
    "print(\"Most probable class is {}, with probability {}\".format(np.argmax(classProbabilities),np.max(classProbabilities)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Test the classifier with synthetic images\n",
    "The second exercise was to create an artificial image, to practice a bit more Numpy tensor manipulation. You could also consider using a Python library for drawing lines etc. into Numpy arrays, e.g., skimage\n",
    "\n",
    "Here, we simply use np.zeros() to create images with all pixels zero, and then use tensor indexing to set some pixels to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#MNIST images are 28x28 pixels\n",
    "image1=np.zeros([28,28])\n",
    "#Draw a vertical bar. Note: The usual convention expected by Numpy and Tensorflow is that \n",
    "#in 2D tensors representing images, the first dimension denotes vertical position and second denotes horizontal\n",
    "image1[5:22,14:16]=1\n",
    "#Visualize\n",
    "pp.imshow(image1)\n",
    "#Test classification. \n",
    "#Note: we reshape the single image into a batch. (Try running the code without to see what error you get!) \n",
    "#Reshaping does not change Tensor contents,\n",
    "#it just changes the way contents are indexed\n",
    "classProbabilities=model.predict(np.reshape(image1,[1,28,28,1]))\n",
    "print(\"Predicted class probabilities: \",classProbabilities)\n",
    "#np.argmax returns the index of the largest value in a Numpy tensor.\n",
    "#np.max returns the largest value\n",
    "print(\"Most probable class is {}, with probability {}\".format(np.argmax(classProbabilities),np.max(classProbabilities)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try changing the position of the number vertically or horizontally and running the code again!** Does it affect the classification? \n",
    "\n",
    "Theory says that a fully connected network is more sensitive to the position, but a convolutional neural network should care less about it.\n",
    "\n",
    "You can change what network you use by re-running one of the network building and training cells above.\n",
    "\n",
    "Also, **try drawing different numbers or patterns.** Can you fool the network with something that doesn't look like a number? This is called an adversarial image, and neural networks are quite prone to them, if trained with too little data that does not contain all the possible types of images and variations the network will be tested with. See also the [Adversarial MNIST tutorial](AdversarialMNIST.ipynb) for an example of how to optimize images to fool the network.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Visualize the images with lowest correct class probabilities\n",
    "This is a good way to gain insights into both 1) the quality of your dataset, and 2) what the network learns.\n",
    "\n",
    "There is a few ways to do this. First, we show how to extract the correct class probabilities from the probability distributions predicted by the network. \n",
    "\n",
    "An alternative is to query the loss function values from the network. The cross-entropy loss is a distance metric between the real class probability distribution and the distribution output by the network. In case of fully known real classes, the real probability distributions are one-hot, i.e., the probability of the correct class is 1 and the other probabilities are zero. This means that finding the image with largest loss is equal to finding the image with lowest correct class probability (for the mathematically inclined, can you figure out why this is the case?). However, getting the loss values out from the network requires either [overriding some Keras callbacks](https://stackoverflow.com/questions/48118111/get-loss-values-for-each-training-instance-keras) or building the network a bit differently, as shown at the bottom of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#We begin by compiling a 2D array that includes both image indices and correct classes\n",
    "#We can get an 1D tensor of indices using np.arange\n",
    "nImages = y_test.shape[0]\n",
    "indices=np.arange(nImages)\n",
    "#Now we can stack both the 1D tensor of indices and the 1D tensor of correct classes\n",
    "#The axis=1 defines the dimension along which to stack\n",
    "classesAndIndices=np.stack([indices,y_test],axis=1)\n",
    "print(\"Classes and indices\",classesAndIndices)\n",
    "\n",
    "#Next, pass the whole test data through the network\n",
    "#This will result in a 2D tensor containing a 1D tensor of class probabilities for each image\n",
    "predictedProbabilities=model.predict(x_test)\n",
    "print(\"Predicted probabilities: \",predictedProbabilities)\n",
    "\n",
    "#Now, we can use the classes and indices to index the probabilities\n",
    "correctClassProbabilities=predictedProbabilities[classesAndIndices[:,0],classesAndIndices[:,1]]\n",
    "print(\"Correct class probabilities: \",correctClassProbabilities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now find the minimum and display the corresponding image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "index=np.argmin(correctClassProbabilities)\n",
    "print(\"Correct class {}, probability {}\".format(y_test[index],correctClassProbabilities[index]))\n",
    "pp.imshow(x_test[index,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we want to show multiple images, we can use np.argsort() to pick the indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sortedIndices=np.argsort(correctClassProbabilities)\n",
    "nImages=8\n",
    "pp.figure(1,figsize=[nImages*3,3])\n",
    "for i in range(nImages):\n",
    "    pp.subplot(1,nImages,1+i)\n",
    "    index=sortedIndices[i]\n",
    "    pp.imshow(x_test[index,:,:,0])\n",
    "    pp.title(\"{}, prob. {:1.5f}\".format(y_test[index],correctClassProbabilities[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just out of curiosity, let's also show the images with high correct class probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sortedIndices=np.argsort(correctClassProbabilities)\n",
    "nImages=8\n",
    "pp.figure(1,figsize=[nImages*3,3])\n",
    "for i in range(nImages):\n",
    "    pp.subplot(1,nImages,1+i)\n",
    "    #we can use negative indexing to index the last elements. Since i starts from 0, we also need to have the \"-1\"\n",
    "    index=sortedIndices[-i-1]\n",
    "    pp.imshow(x_test[index,:,:,0])\n",
    "    pp.title(\"{}, prob. {:1.5f}\".format(y_test[index],correctClassProbabilities[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
