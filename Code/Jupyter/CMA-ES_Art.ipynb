{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract adversarial images synthesized using CMA-ES\n",
    "This notebook shows how to synthesize abstract \"paintings\" through optimization. We use CMA-ES to optimize the corner positions of a number of rectangles. The objective function is the loss function of an MNIST image classifier network, i.e., the optimization finds rectangle configurations that look like numbers to the network. This allows one to visualize what features the network finds essential. Depending on the painting method and network, the results can also be aesthetically interesting.\n",
    "\n",
    "In come cases, like when optimizing raw pixel color values, this kind of adversarial image synthesis can also be done using Tensorflow's optimizers like Adam, as shown in the  [AdversarialMNIST notebook](AdversarialMNIST.ipynb). However, using a population-based method like CMA-ES provides two benefits:\n",
    "\n",
    "* The drawing code does not need to be differentiable and part of the compute graph. \n",
    "\n",
    "* Optimizing highly abstract parametric images limits what kind of exploits the optimization can find; this seems to make the adversarial images more interesting and recognizable to human eye. In contrast, the [AdversarialMNIST notebook](AdversarialMNIST.ipynb) outputs noise with very little structure.\n",
    "\n",
    "NOTE: if your Anaconda environment does not have CMA-ES installed, use ```pip install cma``` from the terminal. You may also need ```pip install scikit-image``` for the drawing methods.\n",
    "\n",
    "**Learning goals:**\n",
    "* Understanding that a convolutional neural network image classifier can be used for image synthesis, when combined with an optimization method.\n",
    "\n",
    "* Using CMA-ES with the ```cma``` python package. \n",
    "\n",
    "**After you've read, run, and understood the code, try to modify it as follows to test your learning:**\n",
    "\n",
    "* Easy: try changing the drawing style, e.g., use lines instead of rectangles.\n",
    "* Slightly harder: try using some other image classifier network. For example, [this repository](https://github.com/geifmany/cifar-vgg) provides pre-trained networks for the CIFAR-10 and CIFAR-100 datasets, i.e., 32x32 pixel images of buildings, birds, boats etc. \n",
    "* Harder: train multiple networks and use their average output probabilities as the objective. How does this affect the results? Papers like [this one](https://arxiv.org/abs/1802.08195) suggest that using an ensemble of multiple networks is harder to fool by adversarial images. \n",
    "* Harder: Make the code run faster by querying the loss function values for a batch of images. This allows Tensorflow to more efficiently parallelize the computation. For this, you probably need to implement the network on a slightly lower level so that you can use sess.run(). See the [AdversarialMNIST notebook](AdversarialMNIST.ipynb) for an example.\n",
    "* Harder: Do the same with audio - fool an audio classifier with parametric sound synthesis\n",
    "* Hard: Implement the same in Unity, feeding a camera texture to the classifier. For example, if you optimize the pose of an animated character, can you synthesize **shadow puppetry**, i.e., make the character's shadow appear as numbers, animals, etc.? For this, you need to use Tensorflow Sharp to load a pretrained classifier network. You can use the (LM-)MA-ES implementation provided in the course repository for the optimization. See the Intelligent Pool for an example of LM-MA-ES.\n",
    "\n",
    "As usual, model solutions are provided for the easy exercises, but please try to think of this as a puzzle game where you first try to solve the puzzles yourself and only check out the walkthrough if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load a pretrained MNIST classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#The pylab inline below is something you may need to make images and plots visible in Jupyter, \n",
    "#depending on your Anaconda setup\n",
    "%pylab inline  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pp\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" #disable Tensorflow GPU usage, a simple example like this runs faster on CPU\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import cma\n",
    "\n",
    "model=keras.models.load_model(\"../../Models/mnist_trained.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import skimage.draw as draw\n",
    "\n",
    "#Line drawing helper\n",
    "def drawLine(image:np.array,r0:int,c0:int,r1:int,c1:int,color:float=1.0):\n",
    "    rr, cc = draw.line(r0,c0,r1,c1)\n",
    "    image[rr, cc] = color\n",
    "\n",
    "#Rectangle drawing helper\n",
    "def drawRectangle(image:np.array,x0,y0,x1,y1,color:float=1.0):\n",
    "    #rectangle(start, extent=extent, shape=img.shape)\n",
    "    xmin=min([x0,x1])\n",
    "    ymin=min([y0,y1])\n",
    "    xmax=max([x0,x1])\n",
    "    ymax=max([y0,y1])\n",
    "    image[ymin:ymax,xmin:xmax]=color\n",
    "    #rr,cc=draw.rectangle(start=(xmin,ymin),extent=(xmax-xmin,ymax-ymin),shape=image.shape)\n",
    "    #image[rr, cc] = color\n",
    "    \n",
    "#Convert a single image to tensorflow image batch\n",
    "def im2batch(image:np.array):\n",
    "    return np.reshape(image,[1,image.shape[0],image.shape[1],1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the optimization is easy as: \n",
    "\n",
    "1) We query for new **x** to evaluate using cmaes.ask()\n",
    "\n",
    "2) Evaluate f(**x**) for each **x**\n",
    "\n",
    "3) Feed the f(**x**) values back to the optimizer using cmaes.tell()\n",
    "\n",
    "4) Repeat until maximum iteration count exceeded\n",
    "\n",
    "However, we must first define some parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#This is how many primitives (in this case: rectangles) we will use\n",
    "nPrimitives=1\n",
    "\n",
    "#How many optimized variables per primitive. \n",
    "#In total, defining the corners of each rectangle requires 4 variables\n",
    "nVarsPerPrimitive=4\n",
    "\n",
    "#How many total optimized variables\n",
    "nVars=nPrimitives*nVarsPerPrimitive\n",
    "print(\"Total number of optimized variables\",nVars)\n",
    "\n",
    "#Width and height of optimized image, 28 for MNIST\n",
    "imageReso=28\n",
    "\n",
    "#Which image class we want to synthesize\n",
    "targetClass=4\n",
    "\n",
    "#Define CMA-ES population size\n",
    "pop_size = 4 + int(3.0*math.log(nVars)) #recommended default for CMA-ES in Hansen's tutorial\n",
    "pop_size*=20  #increase population size because this is a hard problem\n",
    "cmaes_options = {'popsize': pop_size}  #the constructor below needs this\n",
    "\n",
    "#Define initial mean and standard deviation for the variables.\n",
    "#These should be set such that the initial Gaussian distribution of CMA-ES covers the whole range\n",
    "#We use 0 and 1, as we will later use np.sin() or np.tanh() to clamp the values to valid range\n",
    "startingMean=0\n",
    "startingSigma=1\n",
    "\n",
    "#Create the CMA-ES optimizer\n",
    "cmaes=cma.CMAEvolutionStrategy(np.ones(nVars)*startingMean, startingSigma, inopts=cmaes_options)\n",
    "\n",
    "#Variables for remembering the best painting and f(x) value found so far\n",
    "bestArt=None\n",
    "bestFx=np.inf\n",
    "\n",
    "#The main optimization loop\n",
    "nIter=10\n",
    "pp.figure(1,figsize=[nIter*3,3])\n",
    "for iter in range(nIter):\n",
    "    #Ask for a batch of x\n",
    "    xBatch=cmaes.ask()\n",
    "    \n",
    "    #Array to hold the f(x) values\n",
    "    fxBatch=[]\n",
    "    \n",
    "    #Loop over the batch\n",
    "    for x in xBatch:\n",
    "        #Create the drawing:\n",
    "        #First initialize the image to constant color\n",
    "        art=np.ones(shape=[imageReso,imageReso])\n",
    "        \n",
    "        #Make sure that the x given by CMA-ES stays within limits\n",
    "        #You can also try the other two options for slightly different results\n",
    "        x=0.5+0.5*np.sin(x)    #clip without saturating\n",
    "        #x=0.5+0.5*np.tanh(x)  #clip with soft saturation\n",
    "        #x=0.5+0.5*np.clip(x,-1,1) #hard clip\n",
    "        \n",
    "        #Now, we scale to image coordinates. We add the 0.999 to use the range 0...imageReso \n",
    "        #after converting to integers\n",
    "        x=(imageReso+0.999)*x\n",
    "        \n",
    "        #Draw all the rectangles by increasing the brightness of pixel values\n",
    "        for i in np.arange(0,nVarsPerPrimitive*nPrimitives,nVarsPerPrimitive):\n",
    "            drawRectangle(art,int(x[i]),int(x[i+1]),int(x[i+2]),int(x[i+3]),color=0)\n",
    "\n",
    "        #Evaluate the fitness function value. \n",
    "        #model.evaluate() gives us the loss function value and classification accuracy,\n",
    "        #thus model.evaluate()[0] is the loss function value, which we use as the f(x) minimized by CMA-ES \n",
    "        #In addition to the image, we also need the target label as a batch of 1 one-hot vector\n",
    "        labelBatch=np.zeros(shape=[1,10])\n",
    "        labelBatch[0,targetClass]=1\n",
    "        fx=model.evaluate(im2batch(art), labelBatch, verbose=0)[0]\n",
    "        fxBatch.append(fx)\n",
    "\n",
    "        #If we found anew best value, remember the painting for visualization\n",
    "        if fx<bestFx:\n",
    "            bestFx=fx\n",
    "            bestArt=art.copy()\n",
    "    \n",
    "    #Feed the objective function values back to CMA-ES\n",
    "    cmaes.tell(solutions=xBatch,function_values=fxBatch)\n",
    "    \n",
    "    #Print progress\n",
    "    print(\"iter \",iter,\" best f(x) \",bestFx,end='\\r')\n",
    "\n",
    "    #Visualize\n",
    "    pp.subplot(1,nIter,1+iter)\n",
    "    pp.imshow(bestArt)\n",
    "    pp.title(\"Class {}, f(x) {:.5f}\".format(targetClass,bestFx))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run the code with just one black rectangle against a bright background, the results above should how darkening the bottom-left part of the image increases the probability of it being classified as a \"4\". This reflects how in the MNIST training set, fours have more mass at the top and right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a version that optimizes a whole MNIST \"font\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#This is how many primitives (in this case: rectangles) we will use\n",
    "nPrimitives=1\n",
    "\n",
    "#How many optimized variables per primitive. \n",
    "#In total, defining the corners of each rectangle requires 4 variables\n",
    "nVarsPerPrimitive=4\n",
    "\n",
    "#How many total optimized variables\n",
    "nVars=nPrimitives*nVarsPerPrimitive\n",
    "print(\"Total number of optimized variables\",nVars)\n",
    "\n",
    "#Width and height of optimized image, 28 for MNIST\n",
    "imageReso=28\n",
    "\n",
    "#Define CMA-ES population size\n",
    "pop_size = 4 + int(3.0*math.log(nVars)) #recommended default for CMA-ES in Hansen's tutorial\n",
    "pop_size*=20  #increase population size because this is a hard problem\n",
    "cmaes_options = {'popsize': pop_size}  #the constructor below needs this\n",
    "\n",
    "#Define initial mean and standard deviation for the variables.\n",
    "#These should be set such that the initial Gaussian distribution of CMA-ES covers the whole range\n",
    "#We use 0 and 1, as we will later use np.sin() or np.tanh() to clamp the values to valid range\n",
    "startingMean=0\n",
    "startingSigma=1\n",
    "\n",
    "#We will produce a 5-by-2 grid figure\n",
    "pp.figure(1,figsize=[5*3,2*3])\n",
    "\n",
    "#Loop over all 10 MNIST classes\n",
    "for targetClass in range(10):\n",
    "    #Create the CMA-ES optimizer\n",
    "    cmaes=cma.CMAEvolutionStrategy(np.ones(nVars)*startingMean, startingSigma, inopts=cmaes_options)\n",
    "\n",
    "    #Variables for remembering the best painting and f(x) value found so far\n",
    "    bestArt=None\n",
    "    bestFx=np.inf\n",
    "\n",
    "    #The main optimization loop\n",
    "    for iter in range(10):\n",
    "        #Ask for a batch of x\n",
    "        xBatch=cmaes.ask()\n",
    "\n",
    "        #Array to hold the f(x) values\n",
    "        fxBatch=[]\n",
    "\n",
    "        #Loop over the batch\n",
    "        for x in xBatch:\n",
    "            #Create the drawing:\n",
    "            #First initialize the image to constant color\n",
    "            art=np.ones(shape=[imageReso,imageReso])\n",
    "\n",
    "            #Make sure that the x given by CMA-ES stays within limits\n",
    "            #You can also try the other two options for slightly different results\n",
    "            x=0.5+0.5*np.sin(x)    #clip without saturating\n",
    "            #x=0.5+0.5*np.tanh(x)  #clip with soft saturation\n",
    "            #x=0.5+0.5*np.clip(x,-1,1) #hard clip\n",
    "\n",
    "            #Now, we scale to image coordinates. We add the 0.999 to use the range 0...imageReso \n",
    "            #after converting to integers\n",
    "            x=(imageReso+0.999)*x\n",
    "\n",
    "            #Draw all the rectangles by increasing the brightness of pixel values\n",
    "            for i in np.arange(0,nVarsPerPrimitive*nPrimitives,nVarsPerPrimitive):\n",
    "                drawRectangle(art,int(x[i]),int(x[i+1]),int(x[i+2]),int(x[i+3]),color=0)\n",
    "\n",
    "            #Evaluate the fitness function value. \n",
    "            #model.evaluate() gives us the loss function value and classification accuracy,\n",
    "            #thus model.evaluate()[0] is the loss function value, which we use as the f(x) minimized by CMA-ES \n",
    "            #In addition to the image, we also need the target label as a batch of 1 one-hot vector\n",
    "            labelBatch=np.zeros(shape=[1,10])\n",
    "            labelBatch[0,targetClass]=1\n",
    "            fx=model.evaluate(im2batch(art), labelBatch, verbose=0)[0]\n",
    "            fxBatch.append(fx)\n",
    "\n",
    "            #If we found anew best value, remember the painting for visualization\n",
    "            if fx<bestFx:\n",
    "                bestFx=fx\n",
    "                bestArt=art.copy()\n",
    "\n",
    "        #Feed the objective function values back to CMA-ES\n",
    "        cmaes.tell(solutions=xBatch,function_values=fxBatch)\n",
    "\n",
    "        #Print progress\n",
    "        print(\"optimizing number \",targetClass,\", iteration \",iter,\" best f(x) \",bestFx,end='\\r')\n",
    "\n",
    "    #Visualize\n",
    "    pp.subplot(2,5,1+targetClass)\n",
    "    pp.imshow(bestArt)\n",
    "    pp.title(\"Class {}, f(x) {:.5f}\".format(targetClass,bestFx))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, if you used only one rectangle, you should see images reflecting where each number typically has more \"mass\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
