{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract adversarial images synthesized using CMA-ES\n",
    "This notebook shows how to synthesize abstract \"paintings\" through optimization. We use CMA-ES to optimize the corner positions of a number of rectangles. The objective function is the loss function of an MNIST image classifier network. In effect, we will synthesize images using the MNIST classifier as an \"art critic\". This allows us to understand what features the network finds essential. Depending on the painting method and network, the results can also be aesthetically interesting.\n",
    "\n",
    "This is also called adversarial image synthesis, i.e., fooling a trained image classifier. In come cases, this can also be done using Tensorflow's optimizers like Adam, as shown in the  [AdversarialMNIST notebook](AdversarialMNIST.ipynb). However, CMA-ES provides more flexibility, as it does not require the drawing functions to be differentiable. Optimizing something else than raw pixels makes the adversarial images somewhat recognizable to human eye. \n",
    "\n",
    "NOTE: if your Anaconda environment does not have CMA-ES installed, use ```pip install cma``` from the terminal. You may also need ```pip install scikit-image``` for the drawing methods.\n",
    "\n",
    "**Learning goals:**\n",
    "* Using a convolutional neural network image classifier for image synthesis.  \n",
    "* Using CMA-ES with the ```cma``` python package. \n",
    "\n",
    "**After you've read, run, and understood the code, try to modify it as follows to test your learning:**\n",
    "\n",
    "* Easy: try changing the drawing style, e.g., use lines instead of rectangles.\n",
    "* Slightly harder: try using some other image classifier network. For example, [this repository](https://github.com/geifmany/cifar-vgg) provides pre-trained networks for the CIFAR-10 and CIFAR-100 datasets, i.e., 32x32 pixel images of buildings, birds, boats etc. \n",
    "* Harder: train multiple networks and use their average output probabilities as the objective. How does this affect the results? Papers like [this one](https://arxiv.org/abs/1802.08195) suggest that using an ensemble of multiple networks is harder to fool by adversarial images. adding 1 or more fully connected layers, e.g., with 64 neurons before the output layer of the fully connected network example. How do the first layer weights look like now?\n",
    "* Harder: Make the code run faster by querying the loss function values for a batch of images. This allows Tensorflow to more efficiently parallelize the computation. For this, you probably need to implement the network on a slightly lower level so that you can use sess.run(). See the [AdversarialMNIST notebook](AdversarialMNIST.ipynb) for an example.\n",
    "* Harder: Do the same with audio - fool an audio classifier with parametric sound synthesis\n",
    "* Hard: Implement the same in Unity. For example, if you optimize the pose of an animated character, can you make it's shadow appear as numbers, animals, etc.? For this, you need to use Tensorflow Sharp to load a pretrained classifier network and then feed a camera textures to the classifier. You can use the (LM-)MA-ES implementation provided in the course repository for the optimization.\n",
    "\n",
    "As usual, model solutions are provided for the easy exercises, but please try to think of this as a puzzle game where you first try to solve the puzzles yourself and only check out the walkthrough if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load a pretrained MNIST classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "WARNING:tensorflow:From c:\\CondaEnvs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\CondaEnvs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From c:\\CondaEnvs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "#The pylab inline below is something you may need to make images and plots visible in Jupyter, depending on your Anaconda setup\n",
    "%pylab inline  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pp\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" #disable Tensorflow GPU usage, a simple example like this runs faster on CPU\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import cma  #this is the CMA-ES library\n",
    "\n",
    "model=keras.models.load_model(\"../../Models/mnist_trained.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import skimage.draw as draw\n",
    "\n",
    "#Line drawing helper\n",
    "def drawLine(image:np.array,r0:int,c0:int,r1:int,c1:int,color:float=1.0):\n",
    "    rr, cc = draw.line(r0,c0,r1,c1)\n",
    "    image[rr, cc] = color\n",
    "\n",
    "#Rectangle drawing helper\n",
    "def drawRectangle(image:np.array,x0,y0,x1,y1,color:float=1.0):\n",
    "    #rectangle(start, extent=extent, shape=img.shape)\n",
    "    xmin=min([x0,x1])\n",
    "    ymin=min([y0,y1])\n",
    "    xmax=max([x0,x1])\n",
    "    ymax=max([y0,y1])\n",
    "    image[ymin:ymax,xmin:xmax]=color\n",
    "    #rr,cc=draw.rectangle(start=(xmin,ymin),extent=(xmax-xmin,ymax-ymin),shape=image.shape)\n",
    "    #image[rr, cc] = color\n",
    "    \n",
    "#Convert a single image to tensorflow image batch\n",
    "def im2batch(image:np.array):\n",
    "    return np.reshape(image,[1,image.shape[0],image.shape[1],1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the optimization is easy as: \n",
    "\n",
    "1) We query for new **x** to evaluate using cmaes.ask()\n",
    "\n",
    "2) Evaluate f(**x**) for each **x**\n",
    "\n",
    "3) Feed the f(**x**) values back to the optimizer using cmaes.tell()\n",
    "\n",
    "4) Repeat until maximum iteration count exceeded\n",
    "\n",
    "However, we must first define some parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of optimized variables 4\n",
      "(80_w,160)-aCMA-ES (mu_w=42.4,w_1=5%) in dimension 4 (seed=1051707, Mon Apr 22 22:49:10 2019)\n",
      "iter  9  best f(x)  0.0004790976527146995\r"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x216 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#This is how many primitives (in this case: rectangles) we will use\n",
    "nPrimitives=1\n",
    "\n",
    "#How many optimized variables per primitive. \n",
    "#In total, defining the corners of each rectangle requires 4 variables\n",
    "nVarsPerPrimitive=4\n",
    "\n",
    "#How many total optimized variables\n",
    "nVars=nPrimitives*nVarsPerPrimitive\n",
    "print(\"Total number of optimized variables\",nVars)\n",
    "\n",
    "#Width and height of optimized image, 28 for MNIST\n",
    "imageReso=28\n",
    "\n",
    "#Which image class we want to synthesize\n",
    "targetClass=4\n",
    "\n",
    "#Define CMA-ES population size\n",
    "pop_size = 4 + int(3.0*math.log(nVars)) #recommended default for CMA-ES in Hansen's tutorial\n",
    "pop_size*=20  #increase population size because this is a hard problem\n",
    "cmaes_options = {'popsize': pop_size}  #the constructor below needs this\n",
    "\n",
    "#Define initial mean and standard deviation for the variables.\n",
    "#These should be set such that the initial Gaussian distribution of CMA-ES covers the whole range\n",
    "#We use 0 and 1, as we will later use np.sin() or np.tanh() to clamp the values to valid range\n",
    "startingMean=0\n",
    "startingSigma=1\n",
    "\n",
    "#Create the CMA-ES optimizer\n",
    "cmaes=cma.CMAEvolutionStrategy(np.ones(nVars)*startingMean, startingSigma, inopts=cmaes_options)\n",
    "\n",
    "#Variables for remembering the best painting and f(x) value found so far\n",
    "bestArt=None\n",
    "bestFx=np.inf\n",
    "\n",
    "#The main optimization loop\n",
    "nIter=10\n",
    "pp.figure(1,figsize=[nIter*3,3])\n",
    "for iter in range(nIter):\n",
    "    #Ask for a batch of x\n",
    "    xBatch=cmaes.ask()\n",
    "    \n",
    "    #Array to hold the f(x) values\n",
    "    fxBatch=[]\n",
    "    \n",
    "    #Loop over the batch\n",
    "    for x in xBatch:\n",
    "        #Create the drawing:\n",
    "        #First initialize the image to constant color\n",
    "        art=np.ones(shape=[imageReso,imageReso])\n",
    "        \n",
    "        #Make sure that the x given by CMA-ES stays within limits\n",
    "        #You can also try the other two options for slightly different results\n",
    "        x=0.5+0.5*np.sin(x)    #clip without saturating\n",
    "        #x=0.5+0.5*np.tanh(x)  #clip with soft saturation\n",
    "        #x=0.5+0.5*np.clip(x,-1,1) #hard clip\n",
    "        \n",
    "        #Now, we scale to image coordinates. We add the 0.999 to use the range 0...imageReso \n",
    "        #after converting to integers\n",
    "        x=(imageReso+0.999)*x\n",
    "        \n",
    "        #Draw all the rectangles by increasing the brightness of pixel values\n",
    "        for i in np.arange(0,nVarsPerPrimitive*nPrimitives,nVarsPerPrimitive):\n",
    "            drawRectangle(art,int(x[i]),int(x[i+1]),int(x[i+2]),int(x[i+3]),color=0)\n",
    "\n",
    "        #Evaluate the fitness function value. \n",
    "        #model.evaluate() gives us the loss function value and classification accuracy,\n",
    "        #thus model.evaluate()[0] is the loss function value, which we use as the f(x) minimized by CMA-ES \n",
    "        #In addition to the image, we also need the target label as a batch of 1 one-hot vector\n",
    "        labelBatch=np.zeros(shape=[1,10])\n",
    "        labelBatch[0,targetClass]=1\n",
    "        fx=model.evaluate(im2batch(art), labelBatch, verbose=0)[0]\n",
    "        fxBatch.append(fx)\n",
    "\n",
    "        #If we found anew best value, remember the painting for visualization\n",
    "        if fx<bestFx:\n",
    "            bestFx=fx\n",
    "            bestArt=art.copy()\n",
    "    \n",
    "    #Feed the objective function values back to CMA-ES\n",
    "    cmaes.tell(solutions=xBatch,function_values=fxBatch)\n",
    "    \n",
    "    #Print progress\n",
    "    print(\"iter \",iter,\" best f(x) \",bestFx,end='\\r')\n",
    "\n",
    "    #Visualize\n",
    "    pp.subplot(1,nIter,1+iter)\n",
    "    pp.imshow(bestArt)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run the code with just one black rectangle against a bright background, the results above should how darkening the bottom-left part of the image increases the probability of it being classified as a \"4\". This seems to reflects how in the MNIST training set, fours have more mass at the top and right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a version that optimizes a whole MNIST \"font\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of optimized variables 4\n",
      "(80_w,160)-aCMA-ES (mu_w=42.4,w_1=5%) in dimension 4 (seed=1043094, Mon Apr 22 22:45:53 2019)\n",
      "(80_w,160)-aCMA-ES (mu_w=42.4,w_1=5%) in dimension 4 (seed=1113095, Mon Apr 22 22:45:58 2019)\n",
      "(80_w,160)-aCMA-ES (mu_w=42.4,w_1=5%) in dimension 4 (seed=1058668, Mon Apr 22 22:46:03 2019)\n",
      "(80_w,160)-aCMA-ES (mu_w=42.4,w_1=5%) in dimension 4 (seed=1140511, Mon Apr 22 22:46:08 2019)\n",
      "(80_w,160)-aCMA-ES (mu_w=42.4,w_1=5%) in dimension 4 (seed=1152638, Mon Apr 22 22:46:13 2019)\n",
      "(80_w,160)-aCMA-ES (mu_w=42.4,w_1=5%) in dimension 4 (seed=983819, Mon Apr 22 22:46:19 2019)\n",
      "(80_w,160)-aCMA-ES (mu_w=42.4,w_1=5%) in dimension 4 (seed=1058897, Mon Apr 22 22:46:24 2019)\n",
      "(80_w,160)-aCMA-ES (mu_w=42.4,w_1=5%) in dimension 4 (seed=1051756, Mon Apr 22 22:46:29 2019)\n",
      "(80_w,160)-aCMA-ES (mu_w=42.4,w_1=5%) in dimension 4 (seed=1066631, Mon Apr 22 22:46:34 2019)\n",
      "(80_w,160)-aCMA-ES (mu_w=42.4,w_1=5%) in dimension 4 (seed=1054723, Mon Apr 22 22:46:40 2019)\n",
      "optimizing number  9 , iteration  9  best f(x)  0.16543430089950562\r"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#This is how many primitives (in this case: rectangles) we will use\n",
    "nPrimitives=1\n",
    "\n",
    "#How many optimized variables per primitive. \n",
    "#In total, defining the corners of each rectangle requires 4 variables\n",
    "nVarsPerPrimitive=4\n",
    "\n",
    "#How many total optimized variables\n",
    "nVars=nPrimitives*nVarsPerPrimitive\n",
    "print(\"Total number of optimized variables\",nVars)\n",
    "\n",
    "#Width and height of optimized image, 28 for MNIST\n",
    "imageReso=28\n",
    "\n",
    "#Define CMA-ES population size\n",
    "pop_size = 4 + int(3.0*math.log(nVars)) #recommended default for CMA-ES in Hansen's tutorial\n",
    "pop_size*=20  #increase population size because this is a hard problem\n",
    "cmaes_options = {'popsize': pop_size}  #the constructor below needs this\n",
    "\n",
    "#Define initial mean and standard deviation for the variables.\n",
    "#These should be set such that the initial Gaussian distribution of CMA-ES covers the whole range\n",
    "#We use 0 and 1, as we will later use np.sin() or np.tanh() to clamp the values to valid range\n",
    "startingMean=0\n",
    "startingSigma=1\n",
    "\n",
    "#We will produce a 5-by-2 grid figure\n",
    "pp.figure(1,figsize=[5*3,2*3])\n",
    "\n",
    "#Loop over all 10 MNIST classes\n",
    "for targetClass in range(10):\n",
    "    #Create the CMA-ES optimizer\n",
    "    cmaes=cma.CMAEvolutionStrategy(np.ones(nVars)*startingMean, startingSigma, inopts=cmaes_options)\n",
    "\n",
    "    #Variables for remembering the best painting and f(x) value found so far\n",
    "    bestArt=None\n",
    "    bestFx=np.inf\n",
    "\n",
    "    #The main optimization loop\n",
    "    for iter in range(10):\n",
    "        #Ask for a batch of x\n",
    "        xBatch=cmaes.ask()\n",
    "\n",
    "        #Array to hold the f(x) values\n",
    "        fxBatch=[]\n",
    "\n",
    "        #Loop over the batch\n",
    "        for x in xBatch:\n",
    "            #Create the drawing:\n",
    "            #First initialize the image to constant color\n",
    "            art=np.ones(shape=[imageReso,imageReso])\n",
    "\n",
    "            #Make sure that the x given by CMA-ES stays within limits\n",
    "            #You can also try the other two options for slightly different results\n",
    "            x=0.5+0.5*np.sin(x)    #clip without saturating\n",
    "            #x=0.5+0.5*np.tanh(x)  #clip with soft saturation\n",
    "            #x=0.5+0.5*np.clip(x,-1,1) #hard clip\n",
    "\n",
    "            #Now, we scale to image coordinates. We add the 0.999 to use the range 0...imageReso \n",
    "            #after converting to integers\n",
    "            x=(imageReso+0.999)*x\n",
    "\n",
    "            #Draw all the rectangles by increasing the brightness of pixel values\n",
    "            for i in np.arange(0,nVarsPerPrimitive*nPrimitives,nVarsPerPrimitive):\n",
    "                drawRectangle(art,int(x[i]),int(x[i+1]),int(x[i+2]),int(x[i+3]),color=0)\n",
    "\n",
    "            #Evaluate the fitness function value. \n",
    "            #model.evaluate() gives us the loss function value and classification accuracy,\n",
    "            #thus model.evaluate()[0] is the loss function value, which we use as the f(x) minimized by CMA-ES \n",
    "            #In addition to the image, we also need the target label as a batch of 1 one-hot vector\n",
    "            labelBatch=np.zeros(shape=[1,10])\n",
    "            labelBatch[0,targetClass]=1\n",
    "            fx=model.evaluate(im2batch(art), labelBatch, verbose=0)[0]\n",
    "            fxBatch.append(fx)\n",
    "\n",
    "            #If we found anew best value, remember the painting for visualization\n",
    "            if fx<bestFx:\n",
    "                bestFx=fx\n",
    "                bestArt=art.copy()\n",
    "\n",
    "        #Feed the objective function values back to CMA-ES\n",
    "        cmaes.tell(solutions=xBatch,function_values=fxBatch)\n",
    "\n",
    "        #Print progress\n",
    "        print(\"optimizing number \",targetClass,\", iteration \",iter,\" best f(x) \",bestFx,end='\\r')\n",
    "\n",
    "    #Visualize\n",
    "    pp.subplot(2,5,1+targetClass)\n",
    "    pp.imshow(bestArt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, if you used only one rectangle, you should see images reflecting where each number typically has more \"mass\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2env",
   "language": "python",
   "name": "tensorflow2env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
